# Methodology

## Data Source {#sec-data}

The main source of data for this research will be the CHIME/FRB Catalog.
The methods described by @bohanchen_uncloaking_2021, @luo_machinelearningfrb_2022 and @zhuge_machinelearningfrb_2022 is tested against the CHIME/FRB Catalog and not from other telescopes.
Obtaining data from other telescopes presents a bit of a challenge because of the difference in robustness between reporting.
As an example, @the_chimefrbcollaboration_FirstCHIMEFRB_2021 reports the highest frequency and the lowest frequency of a FRB while others do not which was used by @bohanchen_uncloaking_2021 as their input parameter.
Therefore, replicating the methods described above requires reprocessing data from their respective sources to obtain desired properties.
Some links to the raw data is appended in @sec-appendix-raw

## Subclassification Criteria

A close look at @fig-repeater-candidates-Chen2022 reveals that repeaters clump together at different points on the 2D projection.
This could be due to differences between repeaters which was not looked at by the literature.
This research will treat the machine learning result as the initial input for subclass criteria and will be refined further throughout the research.

This research will proceed with the assumption that some data clusters may actually be a single subclass and is separated due to the assumption of the algorithm.
This assumption is also used by @bohanchen_uncloaking_2021 such that even though the paper reports the algorithm finding 9 data clusters of FRB, they put all of them into a binary label of whether it is a 'repeater cluster' or a 'non-repeater cluster'.
We may test whether all of the subclass has statistical difference between each other or only some of them display a significant difference.

## Statistical Test

We will use a statistical test to measure the difference between populations.
The test employed shall not make any assumption about the shape of the distribution of the data because the shape its distribution is still uncertain [@cui_FastRadioBursts_2021; @cui_StatisticalPropertiesFast_2021].
As such, tests such as the Kilmogorov--Smirnov test (KS test) and the Mann--Whitney--Wilcoxon test (MWW test) is adequate for this study because they do not assume the shape of distribution but rather on the differences between the shape of each data's cumulative density function [@ivezic_StatisticsDataMining_2020].
The MWW test have been used by @cui_FastRadioBursts_2021 to test the differences between the intrinsic pulse width and radio luminosities of the repeaters and non-repeaters.

<!-- TODO There must be a name to this resampling(?) method? ðŸ‘‡ -->

To introduce a control to the test, we will swap the labels of the FRBs randomly and test their differences.
The chosen subclassification is expected to show a significant difference rather than choosing a random label.

## Timeline

This study is expected to be conducted in four phases:

1.	Data Exploration. This is the phase where I replicate results from important papers. The aim is to familiarize with the data and methods.
2.  Theoretical Study. This is the phase where I familiarize with the theoretical aspect of fast radio bursts. The aim is to understand the differences and similarities between them and develop suitable methodologies for testing.
3.	Statistical Study. This is the phase where I process the data and test the properties selected in phase 2.
4.  Extrapolation. This is the phase where I the same consideration with data outside of CHIME/FRB. As mentioned in @sec-data, the other telescope requires the raw data to be collected and processed; which is why 'data collection' extends beyond 'Data Exploration'
5.	Thesis writing. This is where I write my dissertation and finish my study.

```{python}
#| warning: false
#| fig-cap: The expected timeline of the different phases of study. The star represents milestones provided by the university. The vertical orange line represents 'now'.
#| label: fig-gantt

import os

import pandas as pd
from pathlib import Path
from sarjana import gantt

DATAPATH = os.getenv('DATAPATH')

progress = pd.read_csv(Path(DATAPATH, 'meta', 'progress-got.csv'), parse_dates=['start', 'end'])
milestones = pd.read_csv(Path(DATAPATH, 'meta', 'milestones.csv'), parse_dates=['date'])
gantt.generate_gantt(progress, milestones=milestones, show=True)
```