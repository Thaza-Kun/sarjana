# Fast Radio Burst Population

![](./_assets/lat_long.svg)
<!-- TODO: Use code to draw -->

## The CHIME/FRB Catalog

The Canadian Hydrogen Intensity Mapping Experiment (CHIME) is a stationary radio telescope located in the southern parts of British Columbia, Canada (49^∘^ 19^'^ 14^''^.52 N,  119^∘^ 37^'^ 25^''^.25 W).
Unlike conventional dish shaped radio telescope, CHIME consists of four 20m x 100m semi-cylindrical reflectors pointed skywards to achieve 8000m^2^ area with a sensitivity between 400 to 800 MHz [@the_chimefrbcollaboration_chime_2018].
This allows the telescope to map ≳200 square degrees of the sky continuously with three different output pipelines: CHIME/Cosmology, CHIME/FRB, and CHIME/Pulsar.
The pipeline relevant to this study is the CHIME/FRB pipeline.

The release of the first CHIME/FRB Data Catalog [@the_chimefrbcollaboration_FirstCHIMEFRB_2021] marks the exponential increase in FRB observation data as it releases a total of 536 bursts detected between 25^th^ July 2018 to 1^st^ July 2019.
We can see in @fig-count-by-telescope that among the 818 FRBs recorded by @spanakis-misirlis_frbstats_2021, 632 (77.1%) bursts^[the count is higher because it includes bursts detected after the catalog's release.] are from the CHIME/FRB dataset.
The CHIME/FRB data is available at [https://www.chime-frb.ca/](https://www.chime-frb.ca/).
The open availability and its well-documented nature makes it easy for researchers to study the FRB population. 

```{python}
#| fig-cap: The number of FRBs detected by individual telescopes as reported in FRBSTATS^[https://www.herta-experiment.org/frbstats/] to illustrate the sheer dominance of FRBs detected by the CHIME/FRB telescope.
#| label: fig-count-by-telescope
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns; sns.set_theme()

frbstats_path = Path('..', 'data', 'raw', 'external', 'FRBSTATS2022-11-23_population.csv')
frbstats_data = pd.read_csv(frbstats_path, parse_dates=['utc'])
frbstats_data['telescope'].replace("CHIME", "CHIME/FRB", inplace=True)
to_plot = frbstats_data[frbstats_data['telescope'].str.contains('Incoherent') == False]
counts = to_plot['telescope'].value_counts()

plt.figure(figsize=(8,4))
ax = sns.countplot(to_plot, y='telescope', order=counts.index)
for i in range(len(counts.index)):
    ax.text(counts[i]+0.25,i, str('{}%'.format(round(counts[i]/sum(counts)*100, 1))), fontdict=dict(
        color='black',
        fontsize=8,
        verticalalignment='center',
    ))
# plt.xticks(rotation=90)
plt.show()
```

## Repeating and Non-Repeating FRB

## Potentially Repeating FRB

The only obvious differentiation of FRB is whether it is seen to repeat or not.
@spanakis-misirlis_frbstats_2021 reports a total of 208 (25.3%) detections are associated with 24 repeater sources while 614 (74.7%) detections are non-repeating^[https://www.herta-experiment.org/frbstats as of 14th Jan 2023].

It is important to note that there is no guarantee that non-repeating FRBs will not repeat. Authors such as @pleunis_fast_2021, @bohanchen_uncloaking_2021, @zhuge_machinelearningfrb_2022 and @luo_machinelearningfrb_2022 tried to predict which non-repeating FRB has the potential to repeat using differing strategies.

<!-- TODO Pleunis -->

### Using Machine Learning

<!-- TODO: Cite VanDerPlas Python, Data Science and Machine Learning -->
Machine learning is a set of task designed for a computer to draw more refined conclusions about a dataset so as to be able to make confident predictions about unseen data, usually by running an algorithm iteratively and self-tuning its hyperparameters.
Algorithms of machine learning are divided into two types: supervised and unsupervised learning [@vanderplas_PythonDataScience_2016].
A supervised learning is when the input data is labelled where the computer will try to predict the label of unseen data as the result of its training.
In contrast, an unsupervised learning is when the input data is unlabelled where the computer will try to predict the relationships between data features to uncover a pattern.

@bohanchen_uncloaking_2021 uses unsupervised machine learning to uncover hidden relationships between FRBs.
Inferring relationships directly from multi-dimensional features of FRBs is hard so they make use of a machine learning technique called 'dimensional reduction' where 13 features (10 observational + 3 model-dependent) are reduced to a 2-dimensional projection space.
The authors found that repeater FRBs tend to be very close to each other in the projection space and concluded, with the help of a clustering algortihm, that non-repeating FRBs which formed groups with said repeaters are potentially repeating.

![A 2D projection space for 13 features of FRBs using the _Uniform Manifold Approximation and Projection_ (UMAP) algorithm [@mcinnes_UMAP_2018]. Note that the x and y direction of a UMAP projection has no specific meaning. However, the algorithm prioritizes preserving the local structure of the data set therefore the formation of clumps means that they are related to each other. The grouping is identified using Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) [@campello_HDBSCAN_2013]. The 13 features are (i) boxcar width, (ii) intrinsic width, (iii) peak flux, (iv) fluence, (v) scattering time, (vi) spectral index, (vii) spectral running, (viii) highest frequency, (ix) lowest frequency, (x) peak frequency, (xi) redshift, (xii) radio energy, and (xiii) rest-frame intrinsic duration. Parameters xi-xiii are model dependent.](./_assets/repeater-candidates_NC_Chen2022.jpg){#fig-repeater-candidates-Chen2022 width=50%}

@luo_machinelearningfrb_2022 and @zhuge_machinelearningfrb_2022 utilizes both supervised and unsupervised learning with the methods split into two papers. 
Their approach is not to choose any one particular algorithm as a single model but uses multiple runs of multilple algorithms and identify shared classifications.
The supervised learning used by @luo_machinelearningfrb_2022 includes decision tree method, random forest method, support vector machine method, and the nearest centroid method; where all of them are classification algorithms.
The unsupervised learning used by @zhuge_machinelearningfrb_2022 includes both dimensional reduction algorithms and clustering algorithms similar to @bohanchen_uncloaking_2021 but different in the way that multiple algorithms of the same task is used such as Pricipal Component Analaysis (PCA), T-distributed Stochastic Neighbour Embedding (T-SNE), and UMAP for dimensional reduction and k-means algorithm and HDBSCAN for the clustering algorithm.

<!-- TODO: Diagram the different workflow -->

There is still no consensus on which model best fit the use case of identifying potentially repeating FRBs.
In spite of that, the fact that algorithms can identify that repeaters are similar to each other than to non-repeaters without knowledge of its repeating nature shows that there is an underlying difference between repeaters and non-repeaters.
It can be said that some non-repeating FRBs that is potentially repeating FRB have latent features of true repeaters [@bohanchen_uncloaking_2021].
